# 大模型技术与发展

## 1. 大模型发展概览

### 1.1 大语言模型定义

**大语言模型**：能够理解和生成人类自然语言的 AI 系统，是一门人工智能技术

- 通过在海量无标注的数据上进行自监督训练，学习到了大量的语言知识和世界知识
- 通过自然语言交互能够完成多种任务，具备了多场景、多用途、跨学科的任务处理能力

### 1.2 发展历程

人工智能技术发展的结果：从小数据到大数据，再从小模型到大模型，从专用领域到通用领域

**演进路径**：

```
统计语言模型（特定任务工具，n-gram models）
  ↓
神经语言模型（任务独立的特征提取器，Word2Vec）
  ↓
预训练语言模型（可迁移的 NLP 任务求解器，ELMO, BERT, GPT-1/2）
  ↓
大规模语言模型（通用任务求解器，GPT-3/4, ChatGPT, Claude）
```

### 1.3 概念范畴

- 预训练语言模型（Pre-trained Language Model）
- 大模型（Large Language Model）
- 垂域大模型（Domain-Specific LLM）
- 多模态大模型（Multimodal LLM）
- 智能体大模型（Agent-based LLM）


## 2. 预训练模型

**语言模型训练的新范式**：提升模型在特定任务上的表现性能

- **代表模型**：BERT, ELMO, GPT-1/2
- **训练方式**：大规模数据上自监督预训练，需要经过微调适配各类任务
- **核心优势**：能够有效利用大数据、大模型、大算力
- **应用场景**：语言理解和文本生成

### 2.1 模型类型

根据架构划分为三大类型：

- **编码器模型**（Encoder-only）
- **解码器模型**（Decoder-only）
- **编解码模型**（Encoder-Decoder）

### 2.2 建模方式分类

根据预训练模型构建的角度进行划分：

#### 2.2.1 编码器模型：掩码语言建模（MLM）

- **英文**：Masked Language Modeling
- **核心思想**：随机遮盖部分词，让模型预测被遮盖的词
- **优点**：能够充分理解上下文，语言理解能力较好
- **缺点**：不擅长生成
- **代表模型**：BERT, RoBERTa, ALBERT

#### 2.2.2 解码器模型：自回归语言建模（AR）

- **英文**：Auto-Regressive Language Modeling
- **核心思想**：根据已经出现的上下文预测下一个词，并把预测的词加入到上下文中
- **优点**：天然适合生成类任务，容易构造大规模的训练数据
- **缺点**：无法充分利用双向上下文
- **代表模型**：LLaMA, GPT-1/2

#### 2.2.3 编解码模型：序列到序列建模（Seq2Seq）

- **英文**：Sequence to Sequence Modeling
- **核心思想**：编码器理解输入，解码器生成输出
- **优点**：适合序列到序列转换任务
- **代表模型**：BART, T5, ProphetNet

### 2.3 模型架构

#### 2.3.1 RNN 架构

- **核心思想**：通过循环神经网络，利用上下文信息
- **优点**：适合处理序列数据
- **缺点**：无法并行计算，计算效率低
- **代表模型**：LSTM, GRU

#### 2.3.2 Transformer 架构

- **自注意力机制**：完全摒弃 RNN 循环机制，通过注意力机制进行全局处理
- **QKV 权重矩阵**：采用三个权重矩阵（Query, Key, Value），捕捉上下文信息
- **多层网络**：每层由多头注意力机制和前馈网络构成
- **位置编码**：通过添加位置编码，让模型能够理解输入序列的顺序


## 3. 大规模语言模型

### 3.1 大模型概览

大规模语言模型（Large Language Models, LLMs）是预训练模型发展到一定规模后产生的新范式，具备强大的泛化能力和涌现能力。

### 3.2 大模型训练范式变化

| 维度 | 传统方式 | 大模型方式 |
|------|---------|-----------|
| **技术方式** | 独立任务的个体化专门训练 | 大厂中心化的预训练 + 后训练（微调、提示学习、上下文学习、思维链提示、工作流编排）|
| **数据规模** | 中小规模数据 | 海量数据 |
| **算力规模** | 单机 | 分布式 → 云 |
| **训练内容** | 独立的任务形态 | 统一的序列到序列的建模形态，能够处理各种任务 |

### 3.3 大规模语言模型核心特征

- **本质**：通过强大算法利用大量算力在海量数据上训练出的概率预测函数
- **特性**：泛化能力强、理解能力强、出现涌现能力

### 3.4 预训练模型 vs 大规模语言模型

| 角度 | 预训练模型 | 大规模语言模型 |
|------|-----------|---------------|
| **典型模型** | ELMO, BERT, GPT-1/2 | GPT-3/4, ChatGPT, Claude |
| **模型结构** | RNN, Transformer | Transformer |
| **注意力机制** | RNN, Transformer | Transformer |
| **训练方式** | 判别式预训练 | 生成式预训练 |
| **训练机制** | 去噪自编码 | 自回归生成 |
| **训练数据** | 特定任务自然语言 | 多元化数据：自然语言、公式、代码、图像、视频、音频 |
| **擅长任务类型** | 理解、判断 | 生成 |
| **模型规模** | 10B 参数以下规模 | 大于 10B 参数 |
| **下游任务应用方式** | 微调 | 微调 + 提示学习 |
| **模型架构** | 双向 Transformer | 单向 Transformer |


### 3.5 关键技术

#### 3.5.1 预训练（Pre-training）

| 要素 | 说明 |
|------|------|
| **数据** | 海量无标注数据 |
| **目标** | 学习通用语言知识、世界知识以及逻辑相关知识等 |
| **输出模型** | 基础模型（Base Model）|
| **耗时** | 数月 |
| **资源** | 大规模 GPU 集群 |
|**不足**|不懂如何"听从指令"，完成具体任务|

#### 3.5.2 微调（Fine-tuning）

| 要素 | 说明 |
|------|------|
| **数据** | 大量高质量指令数据，如数万条用户指令数据及对应答案，形式{"instruction": "请翻译这个中文句子","input":"你好","output":"hello"} |
| **目标** | 在预训练的基础上增加任务适配能力，提升模型在多样化任务上的表现能力，让文本输出更加可控 |
|**提升机制**|1.任务格式对齐：理解人类指令的格式；2.任务能力激活，预训练模型已经具备很多能力，需要通过特定指令训练进行激活；3.多任务泛化能，获取任务理解的元能力|
| **输出模型** | SFT 模型（Supervised Fine-Tuned Model）|
| **耗时** | 数天 |
| **方式** | 传统微调和 FLAN 指令微调 |

##### FLAN 指令微调

**FLAN**（Fine-tuned Language Net）是谷歌提出的一种新的指令微调方式，用于提升模型在未见任务上的泛化能力。

| 维度 | 传统微调 | FLAN 指令微调 |
|------|---------|--------------|
| **训练数据** | 单一任务的标注数据 | 多任务的指令-响应对 |
| **目标** | 优化特定任务的性能 | 优化多任务和泛化性能 |
| **泛化能力** | 任务内泛化 | 任务内泛化 + 跨任务泛化 |
| **零样本能力** | 有限 | 跨任务零样本能力 |
| **适应新任务** | 需要重新微调 | 通过新指令即可适应 |

**实现方式**：

构建高质量的指令-输入-输出三元组，将 62 个不同的 NLP 任务划分为 12 个指令模板：

1. **Natural Language Inference**（7 datasets）：ANLI, RTE, CB, SNLI, MNLI, WNLI, QNLI
2. **Commonsense**（4 datasets）：COPA, HellaSwag, PIQA, StoryClose
3. **Sentiment**（4 datasets）：SST-2, IMDB, Sent140, Yelp
4. **Paraphrase**（4 datasets）：MRPC, QQP, PAWS, STS-B
5. **Closed-book QA**（3 datasets）：ARC, NQ, TQA
6. **Struct to Text**（4 datasets）：CommonGen, DART, E2ENLG, WEBNLG
7. **Translation**（8 datasets）：WMT 和 ParaCrawl
8. **Reading Comprehension**（5 datasets）：BoolQ, OBQA, DROP, SQuAD, MultiRC
9. **Reading Comp. w/ Commonsense**（2 datasets）：ReCoRD, CosmosQA
10. **Coreference**（3 datasets）：DPR, Winogrande, WSC273
11. **Misc**（7 datasets）：CoQA, TREC, QuAC, CoLA, WiC, MAIN, Fix Punctuation
12. **Summarization**（11 datasets）：AESLC, Multi-News, SamSum, AG News, Newsroom, Wiki Lingua EN, CNN/DM, Open-ABS Delegate, XSUM, Gigaword, Open-Abs Movie

#### 3.5.3 对齐（Alignment）

| 要素 | 说明 |
|------|------|
| **数据** | 标注对比数据，数十万至百万级标注对比对，以及用户指令 |
| **输出模型** | 对齐模型（Aligned Model）|
| **目标** | 对齐人类的偏好、价值观、安全、意图；生成更加安全、健康、无毒、受人喜爱的答案；大幅减少有害和失真信息的输出 |
| **原则** | 有用（Helpful）、诚实（Honest）、无害（Harmless）|
| **耗时** | 数天 |

**技术流程**：

1. **数据集演进**：SFT 数据集 → RM（Reward Model）数据集 → RL（Reinforcement Learning）数据集
2. **模型演进**：SFT 模型 → RM 模型 → RL 模型
3. **训练步骤**：Supervised Fine-Tuning → Reward Model → Reinforcement Learning

### 3.6 大模型特性

#### 3.6.1 扩展定律（Scaling Law）

模型性能随着模型规模（参数大小）、算力大小的增加，而呈现幂律增长的趋势。

#### 3.6.2 涌现能力（Emergent Abilities）

模型参数达到一定规模时，某些能力（如理解、编程、推理）会大幅提升，同时出现很多小模型不具备的能力。

#### 3.6.3 幻觉（Hallucinations）

模型生成的文本不具备确定性，或者会生成不符合事实的文本。

### 3.7 主流大模型系列

#### 3.7.1 GPT 系列

| 模型 | 特点 |
|------|------|
| **GPT-1** | 单向自回归建模 + 有监督微调，探索"预训练 + 微调"范式下的自然语言理解能力 |
| **GPT-2** | 单向自回归建模 + 更多参数、更多数据，探索基于自然语言的多任务解决能力 |
| **GPT-3** | 探索了千亿参数规模的语言模型能力，提出了基于"上下文学习"的任务解决方法 |
| **GPT-3.5 / ChatGPT** | 指令微调 + 人类反馈 + 对话优化 |
| **GPT-4** | 多模态能力、更长的上下文理解与处理能力、更高效的训练与预测、更广泛的高价值应用场景 |

#### 3.7.2 LLaMA 系列

| 模型 | 特点 |
|------|------|
| **LLaMA-1** | 7B-65B + 预训练 + 2K 上下文 |
| **LLaMA-2** | 7B-70B + 预训练 + 指令微调 + RLHF + 4K 上下文 |
| **LLaMA-3** | 8B-70B + 预训练 + 指令微调 + DPO + 8K 上下文 |
| **LLaMA-3.1/3.2** | 8B-405B + 预训练 + 指令微调 + DPO + 128K 上下文 |

#### 3.7.3 Qwen 系列

| 模型 | 特点 |
|------|------|
| **Qwen 1.5** | Model Scaling 向更大和更小扩展，MoE, AWQ/GGUF |
| **Qwen 2** | 多语言增强，长文本能力增强 |
| **Qwen 2.5** | 数学、代码能力增强，多语言增强 |

#### 3.7.4 DeepSeek 系列

| 模型 | 特点 |
|------|------|
| **DeepSeek LLM** | 70B + DenseLLM + 2T token 中英语料 + 预训练 + SFT + DPO |
| **DeepSeek V2** | 236B + MoE + 8.1T token 中英语料 + 预训练 + SFT + DPO |
| **DeepSeek V2.5** | 基于 V2，强化了通用任务能力和代码能力 |
| **DeepSeek V3** | 671B + MoE + 14.8T token 中英语料 + 预训练 + SFT + DPO，引入 Auxiliary-loss-free strategy 进行专家均衡，Multi-Token Prediction training 提升模型性能和加速推理，FP8 混合精度降低训练和推理开销 |
| **DeepSeek R1** | 14.8T token 语料，训练范式：Base 模型 + 多阶段训练 + 冷启动训练 + 强化学习 |

### 3.8 大模型部署

#### 3.8.1 部署方式

| 方式 | 说明 |
|------|------|
| **API 调用** | 根据大模型供应商文档，获取调用权限，编写相关代码，调用 API 接口 |
| **本地部署** | 安装 Ollama 等工具，运行特定模型 |

## 4. 大模型概念延伸

### 4.1 垂域大模型

垂域大模型（Domain-Specific LLM）是针对特定领域优化的大语言模型。

- **基本范式**：在通用大模型的基础上进行领域训练增强
- **核心优势**：专业性强、成本效益好、合规性好
- **训练方式**：领域数据训练（预训练、微调、提示）、检索增强（RAG）等
- **常见领域**：教育、医疗、法律、金融等

### 4.2 多模态大模型

多模态大模型（Multimodal LLM）是大模型前沿发展的新趋势和焦点。

- **核心价值**：极大扩展大模型能力边界和应用场景，成为智能跃迁的下一个关键引擎
- **常见模态**：文本、图像、视频、语音等
- **通用工作模式**：多模态编码 → 特征融合模块 → 多模态解码
- **前沿会议**：CVPR, MM, COLING

### 4.3 智能体

智能体（Agent）是基于大模型构建的自主智能系统。

- **定义**：基于大模型构建，能够动态指导自身流程和工具使用，并根据实时反馈调整自己操作的系统
- **核心特点**：
  - 具备自主和进化的能力
  - 能够进行环境交互（感知理解、规划决策、动作落实）
  - 持久运行能力（反思优化、迭代演化、安全防护）
- **知识更新**：知识库、经验等
- **集成工具**：APP、API、函数等
- **核心意义**：极大扩展大模型能力边界和应用场景

---

## 参考资料

- GPT 系列论文
- LLaMA 系列技术报告
- Transformer 原始论文：*Attention Is All You Need*
- FLAN 论文：*Finetuned Language Models Are Zero-Shot Learners*












   



