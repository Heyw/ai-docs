# 大模型技术与发展

## 1.大模型发展概览
**大语言模型定义**： 能够理解和生成人类自然语言的AI系统，是一门人工智能技术;
- 通过在海量无标注的数据上进行自监督训练，学习到了大量的语言知识和世界知识；
- 通过自然语言交互能够完成多种任务，具备了多场景，多用途，跨学科的任务处理能力；
**发展历程**：
- 人工智能技术发展的结果：从小数据到大数据，再从小模型到大模型，从专用领域到通用领域
- 示例：
 统计语言模型(特定任务工具，n-gram models)
 ->神经语言模型(任务独立的特征提取器,word2vec)
 ->预训练语言模型(可迁移的NLP任务求解器,ELMO,BERT,GPT-1/2)
 ->大规模语言模型(通用任务求解器, GPT-3/4,chatGPT,claude)

 **概念范畴**: 预训练语言模型，大模型，垂域大模型，多模态大模型，智能体大模型


## 2.预训练模型
   **语言模型训练的新范式**: 训练模型在特定任务上的表现性能
   - 代表模型： Bert,Elmo,GPT-1/2
   - 大规模数据上自监督预训练，需要经过微调适配各类任务，能够有效利用大数据，大模型，大算力
   - 能够用于语言解析和和生成

  ### 2.1类型
   - 编码器模型
   - 解码器模型
   - 编解码模型

  ### 2.2分类方式
   **建模视角**：根据预训练模型构建的角度进行划分
   - 编码器模型: 掩码语言建模(Mask language modeling)
    **核心思想**: 随机遮盖部分词，让模型预测被遮盖的词
    **优点**: 能够充分理解上下文，语言理解能力较好
    **缺点**: 不擅长生成
    **代表模型**: Bert, RoBertTa,Albert
   - 解码器模型： 自回归语言建模(Auto-regressive language modeling)
    **核心思想**: 根据已经出现的上下文预测下一个词，并把预测的词加入到上下文中
    **优点**: 天然适合生成类任务，容易构造大规模的训练数据
    **缺点**: 无法充分利用双向上下文
    **代表模型**: Llama, GPT-1/2
   - 编解码模型: 序列到序列建模(sequence to sequence modeling)
    **核心思想**: 编码器理解输入，解码器生成输出
    **优点**: 适合从序列到序列任务
    **代表模型**: BART, T5, ProphetNet

  ### 2.3模型架构
  - RNN
    **核心思想**: 通过循环神经网络，利用上下文信息
    **优点**: 适合处理序列数据
    **缺点**: 无法并行计算，计算效率低
    **代表模型**: LSTM, GRU
  - Transformer
    **自注意力机制**: 完全摒弃RNN循环机制，通过注意力机制进行全局处理
    **QKV权重矩阵**: 采用三个权重矩阵(Q,K,V)，捕捉上下文信息
    **多层网络**: 每层由多头注意力机制和前馈网络构成
    **位置编码**: 通过添加位置编码，让模型能够理解输入序列的顺序


## 3.大规模语言模型

### 3.1 大模型概览

### 3.2 大模型训练范式变化
- 技术方式变化：独立任务的个体化专门训练->大厂中心化的预训练+后训练(微调，提示学习(上下文学习，思维链提示，工作流编排))
- 数据规模变化：中小规模数据->海量数据
- 算力规模变化：单机->分布式->云
- 训练内容变化: 独立的任务形态->统一的序列到序列的建模形态，能够处理各种任务

### 3.3 大规模语言模型
**本质**: 通过强大算法利用大量算力在海量数据上训练出的概率预测函数
**特性**: 泛化能力强，理解能力强，出现涌现能力
**比较**
| 角度 | 预训练模型 | 大规模语言模型 |
| --- | --- | --- |
| 典型模型 | ELmo,Bert,GPT-1/2 | GPT-3/4,chatGPT,claude |
| 模型结构 | RNN,Transformer | Transformer |
| 注意力机制 | RNN,Transformer | Transformer |
| 训练方式| 判别式预训练 | 生成式预训练 |
|训练机制|去噪自编码|自回归生成|
| 训练数据 | 特定任务自然语言 |多元化数据，自然语言，公式，代码，图像，视频，音频   |
| 擅长任务类型 | 理解，判断 | 生成 |
| 模型规模 | 10B参数以下规模 | 大于10B参数 |
| 下游任务应用方式 | 微调 | 微调加提示学习 |
| 模型架构 | 双向Transformer | 单向Transformer |


### 3.4 关键技术
#### 3.4.1预训练
- 数据：海量无标注数据
- 目标：学习通用语言知识，世界知识，以及逻辑相关知识等
- 模型: 基础模型
- 耗时：数月
- 资源： 大规模GPU集群

#### 3.4.2微调
- 数据：高质量指令数据，如数万用户的指令数据以及答案数据
- 目标：大幅提升模型在各个任务上的表现能力以及让文本输出更加可控
- 模型: SFT模型(Superived Fine-tuned)
- 耗时：数天
- 方式：传统微调和FLAN微调

**FLAN指令微调**
 Fine-tuned Language net是谷歌提出来的一种新的指令微调方式，用于提升模型在未见任务上的泛化能力。
| 维度 | 传统微调 | FLAN指令微调 |
| --- | --- | --- |
| 训练数据 | 单一任务的标注数据 | 多任务的指令响应对 |
| 目标 | 优化特定任务的性能 | 优化特定任务和泛化性能 |
| 泛化能力 | 任务内泛化 | 任务内泛化，跨任务泛化 |
| 零样本能力 | 有限 | 有限，跨任务零样本 |
| 适应新任务 | 需要重新微调 | 通过新指令即可适应 |
**实现方式**
构建高质量的指令-输入-输出三元组；
构建方式将62个不同的NLP任务划分为12个指令模板：
- Natural language inference(7 dataset): ANLI,RTE,CB,SNLI,MNLI WNLI,QNLI
- Commonsense(4 dataset): COPA,HellaSwag,PIQA,StoryClose
- Sentiment(4 dataset): SST-2,IMDB,Sent140,Yelp
- Paraphrase(4 dataset): MRPC,QQP,PAWB,STS-B
- Closed-book QA(3 dataset): ARC,NQ,TQA
- Struct to text(4 dataset): CommonGen,DART,E2ENLG,WEBNLG
- Translation(8 dataset)：WMT和ParamCrawl
- Reading comp(5 dataset):BoolQ,OBQA,DROP,SQuAD,MultiRC
- Read.comp.w/conmmonsense(2 dataset): ReCoRD,CosmosQA
- Coreference(3 dataset): DPR,Winogrande,WSC273
- Misc(7):CoQA,TREC,QuAC,ColA,WIC,Main,Fix Punctutiation
- Summarization(11): AESLC,Multi-News,SamSum,AG News,Newsroom,Wiki Lingua EN,CNN DM,Open-ABS iDelegate,XSUM,Gigaword,Open-Abs Moive

#### 3.4.3对齐
- 数据: 标注对比对，十数万至百万标注对比对，与用户指令
- 模型: 对齐模型
- 目标： 对齐人类的偏好，价值观，安全,意图;生成更加安全，健康，无毒，受人喜爱的答案；大幅减少有害和失真信息的输出
- 原则： 有用，城市，无害
- 耗时：数天
**技术要点**
- 数据集： SFT数据集->RM(Reward Model)数据集->RL(Reinforcement Learning)数据集
- 模型： SFT模型->RM模型->RL模型
- 步骤： Surprised Fine-Tunel->Reward Model->Reinforcement Learning

### 3.5大模型特性
**扩展定律(Scaling law)**
模型性能随着模型规模(参数大小)，算力大小的增加，而呈现幂律增长的趋势
**涌现能力(Emergent Ablilities)**
模型参数达到一定规模时，某些能力(如理解，编程，推理)会大规模提升，同时出现很多小模型不具备的能力
**幻觉(Hallucinations)**
模型生成的文本不具备确定性，或者会生成不符合事实的文本

### 3.6大模型系列
**GPT系列**
- GPT-1: 单向自回归建模+有监督微调，探索'预训练+微调'范式下的自然语言理解能力
- GPT-2: 单向自回归建模+更多参数，更多数据的模型，探索基于自然语言的多任务解决能力
- GPT-3: 探索了千亿参数规模的语言模型能力，提出了基于"上下文学习"的任务解决方法
- GPT-3.5/ChatGpt:指令微调+人类反馈+对话优化
- GPT-4: 多模态能力，更长的上下文理解与处理能力，更高效的训练与预测，更广泛的高价值应用场景

**LLama系列**
- LLamma-1: 7B-65B+预训练+2K上下文
- LLama-2: 7B-70B+预训练+指令微调+RLHF+4k上下文
- LLama-3: 8B-70B+预训练+指令微调+DPO+8k上下文
- LLama-3.1,3.2: 8B-405B+预训练+指令微调+DPO+1321上下文

**Qwen系列**
- Qwen1.5: Model Scaling向更大和更小扩展，Moe,AWQ/GGUF
- Qwen2: 多语言增强，长文本能力增强
- Qwen2.5: 数学，代码能力增强，多语言增强
**DeepSeek系列**
- DeepSeek LLM: 70B+DenseLLM+ 2T token中英语料+ 预训练+SFT+DPO
- DeepSeek V2: 236B+Moe+8.1T token中英语料+预训练+SFT+DPO
- DeepSeek V2.5:基于v2,强化了通用任务能力和代码能力
- DeepSeek V3: 671B+Moe+14.8T token中英语料+预训练+SFT+DPO+，并引入了Auxiliary-loss-free strategy进行专家均衡，Multi-Token Predication training提升模型性能和加速退，FP8混合精度降低训练和推理开销
- DeepSeek R1: 14.8T token语料,训练范式：base模型+多阶段训练+冷启动训练+强化学习

### 大模型部署
**部署方式**
- API调用: 根据大模型供应商文档，获取大模型调用权限，编写相关代码，调用API接口
- 本地部署： 安装Ollama,运行特定模型

## 4.大模型概念延申

### 4.1垂域大模型
- 基本范式：在通用大模型的基础上进行领域训练增强，专业性强，成本效益好，合规性好
- 训练方式: 领域数据训练(预训练，微调，提示)，检索增强等
- 常见领域: 教育，医疗，法律，金融等

### 4.2多模态大模型的前沿发展
- 多模态大模型的能力突破，成为大模型前沿发展的新趋势和焦点
- 极大扩展大模型能力边界和应用场景，智能跃迁的下一个关键引擎
- 常见模态： 文本，图像，视频，语音等
- 通用工作模式: 多模态编码->特征融合模块->多模态解码
- 前沿教程: CVPR,MM,COLING

### 4.3智能体
- 定义: 基于大模型构建，能够动态指导自身流程和工具使用，并根据实时反馈调整自己操作的系统
- 特点： 具备自主和进化的能力，能够进行环境交互(感知理解，规划决策，动作落实)和持久运行(反思优化，迭代演化，安全防护)的能力
- 知识更新： 知识库，经验等
- 集成工具: APP,API,函数等
- 意义： 极大扩展大模型能力边界和应用场景












   



